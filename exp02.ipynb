{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd01b4c7016e99d31c2e7c892573dc93dbd4548eb0a0f5dca22fbf3a690830b4e66",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_example_paths = glob.glob('data/train/*.json')\n",
    "test_example_paths = glob.glob('data/test/*.json')\n",
    "\n",
    "train_example_names = [fn.split('.')[0] for fn in os.listdir('data/train')]\n",
    "test_example_names = [fn.split('.')[0] for fn in os.listdir('data/test')]\n",
    "\n",
    "metadata = pd.read_csv('data/train.csv')\n",
    "metadata_train = metadata.loc[metadata.Id.isin(train_example_names)]\n",
    "metadata_test = metadata.loc[metadata.Id.isin(test_example_names)]\n",
    "\n",
    "metadata = pd.read_csv('data/train.csv')\n",
    "metadata_train = metadata.loc[metadata.Id.isin(train_example_names)]\n",
    "metadata_test = metadata.loc[metadata.Id.isin(test_example_names)]\n",
    "\n",
    "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "def make_single_whitespace(text):\n",
    "    return _RE_COMBINE_WHITESPACE.sub(\" \", text).strip()\n",
    "\n",
    "def remove_punc(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt))\n",
    "\n",
    "def load_train_example_by_name(name):\n",
    "    doc_path = os.path.join('data/train', name + '.json')\n",
    "    with open(doc_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_doc_id(doc_path):\n",
    "    return os.path.split(train_example_names[0])[-1].split('.')[0]\n",
    "\n",
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "# Load dataset names\n",
    "df = pd.read_csv('C:\\projects\\personal\\kaggle\\kaggle_coleridge_initiative\\data\\data_set_26897.csv')\n",
    "us_dataset_names = list(df.title.values)\n",
    "us_dataset_names = [make_single_whitespace(remove_punc(n)).lower() for n in us_dataset_names]\n",
    "\n",
    "labels = list(metadata.cleaned_label.unique())\n",
    "labels = sorted(labels, key = len, reverse = True)\n",
    "labels = [l.strip() for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_bigrams(label):\n",
    "    tokens = label.split(' ')\n",
    "    return [f'{t1} {t2}' for t1, t2 in zip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "for t in ['and', 'was', 'in']:\n",
    "    stop_words.remove(t)\n",
    "\n",
    "banned_kw = [\n",
    "    'STEM', 'FDA', 'SSH', 'FSIZE', 'PET', 'NCATE', 'TESOL', 'AVHRR-OI',\n",
    "    'ICT',\n",
    "    'AAEA',\n",
    "    'BMI', 'ADGC', 'CDRSUM', 'NASS',\n",
    "    'MMSE', 'CDR', 'SPSS', 'LCRP', 'DML', 'ITU', 'DRI', 'CIPSEA', 'IEP', 'NCES', 'BCG', 'HLM', 'MLLW', 'FDG', 'MRMC'\n",
    "]\n",
    "\n",
    "banned_values = [\n",
    "    'laboratory', 'body mass index', 'admission test', 'neural networks', 'accuracy of', 'chain reaction', 'adversarial network',\n",
    "    'state exam', 'reform act', 'least', 'labeling', 'principal components analysis', 'independent components analysis', 'markov chain', 'monte carlo',\n",
    "    'bayesian information', 'family wise error', 'posterior anterior', 'Bidirectional Encoder', 'Morphometry', 'Integral', 'T2*weighted', 'T2-weighted',\n",
    "    'T2weighted', 'T1*weighted', 'T1-weighted', 'T1weighted', 'EMCI', 'Learning Test', 'Gradepoint average', 'doctor of', 'masters of',\n",
    "    'Expected Family Contribution', 'life in', 'Long Short Term', 'Long ShortTerm', 'LSTM', 'lipoprotein', 'Support Vector Machine', 'User Interface',\n",
    "    'National Institute of', 'glucose', 'Research Division', '%', 'Heating Weeks', 'Public Management', 'Theory', 'Middle East respiratory',\n",
    "    'Discriminant Analysis', 'boltzmann', 'Disease Control and Prevention', 'polymorphism', 'positron emission tomography', 'dorsolateral', 'Data Analysis System',\n",
    "    'Analysis Kit', 'Google', 'Principal Analysis', 'Cognitive Impairment', 'Analysis of Variance'\n",
    "    ]\n",
    "\n",
    "banned_after_tokens = stop_words\n",
    "\n",
    "banned_values = [b.lower() for b in banned_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_abbr_in_parantheses(match, doc_text):\n",
    "    try:\n",
    "        match_i = doc_text.index(f'({match})')\n",
    "    except:\n",
    "        try:\n",
    "            match_i = doc_text.index(f'({match};')\n",
    "        except:\n",
    "            match_i = doc_text.index(f'({match}')\n",
    "\n",
    "    match_nopunc = remove_punc(match).replace(' ', '')\n",
    "    n_tokens = len(match_nopunc.replace(' ', ''))\n",
    "\n",
    "    slice_start_i = max(match_i - 200, 0)\n",
    "    slice_end_i = min(match_i + len(match) + 40, len(doc_text))\n",
    "    doc_slice = doc_text[slice_start_i: slice_end_i]\n",
    "    \n",
    "    # Remove dates\n",
    "    doc_slice = re.sub(r'(19|20)[0-9][0-9]', ' ', doc_slice)\n",
    "\n",
    "    # Remove parantheses\n",
    "    doc_slice = doc_slice.replace('(', ' ').replace(')', ' ').replace(';', ' ').replace('-', '').replace('\\n', ' ')\n",
    "\n",
    "    tokens = doc_slice.split(' ')\n",
    "\n",
    "    tokens = [t for t in tokens if len(t) > 0]\n",
    "    match_token_i = tokens.index(match_nopunc)\n",
    "\n",
    "    if match_token_i - n_tokens <= 0:\n",
    "        return [], [], \"\"\n",
    "\n",
    "    start_i = match_token_i-n_tokens\n",
    "    end_i = match_token_i\n",
    "\n",
    "    # If a prev token started with uppercase, use it\n",
    "    try:\n",
    "        if start_i > 1:\n",
    "            if tokens[start_i-2][0].isupper():\n",
    "                start_i -= 2\n",
    "            else:\n",
    "                if tokens[start_i-1][0].isupper():\n",
    "                    start_i -= 1\n",
    "\n",
    "        word_tokens = tokens[start_i:end_i]\n",
    "\n",
    "        # Drop number token if it is coming first\n",
    "        if word_tokens[0].isdigit():\n",
    "            word_tokens = word_tokens[1:]\n",
    "\n",
    "        # Remove 2 lowercase tokens from start\n",
    "        for _ in range(2):\n",
    "            if word_tokens[0][0].islower():\n",
    "                word_tokens = word_tokens[1:]\n",
    "                start_i += 1\n",
    "\n",
    "    except IndexError:\n",
    "        print(f'IndexError for {match}')\n",
    "        return [], [], \"\"\n",
    "\n",
    "    after_token = \"\"\n",
    "    if len(tokens) > match_token_i + 1:\n",
    "        after_token = tokens[match_token_i + 1]\n",
    "\n",
    "    before_tokens = tokens[max(start_i - 3, 0) : start_i]\n",
    "\n",
    "    return before_tokens, word_tokens, after_token\n",
    "\n",
    "\n",
    "def tokens_are_dataset_name(tokens):\n",
    "    if len(tokens) == 0:\n",
    "        return False\n",
    "    \n",
    "    long_tokens = [t for t in tokens if len(t) > 3]\n",
    "    lowercase_count = len([t for t in long_tokens if t[0].islower()])\n",
    "    uppercase_count = len([t for t in long_tokens if t[0].isupper()])\n",
    "\n",
    "    return lowercase_count < 4 and uppercase_count > 0\n",
    "\n",
    "def after_token_ok(after_token):\n",
    "    if after_token == \"\":\n",
    "        return True\n",
    "\n",
    "    if after_token.lower() in banned_after_tokens:\n",
    "        return False\n",
    "\n",
    "    # Probably plural\n",
    "    if after_token not in ['was', 'has', 'is', 'this'] and after_token[-1].lower() == 's':\n",
    "        return False\n",
    "\n",
    "    # Probably a link\n",
    "    if 'http' in after_token:\n",
    "        return False\n",
    "\n",
    "    # A reference. Datasets don't get referenced like that\n",
    "    if '[' in after_token and ']' in after_token:\n",
    "        return False\n",
    "\n",
    "    # Probably a link\n",
    "    if '/' in after_token:\n",
    "        return False\n",
    "\n",
    "    if 'cell' in after_token:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def before_tokens_ok(before_tokens):\n",
    "    if len(before_tokens) == 0:\n",
    "        return True\n",
    "\n",
    "    if 'by' in before_tokens:\n",
    "        return False\n",
    "\n",
    "    if 'adjusted' in before_tokens:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "#get_words_from_abbr_in_parantheses('BDNF', doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6019\n",
    "\n",
    "doc_id = train_example_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6c1062a4-e604-4503-a3d0-c68936db1e74\n['adni', 'alzheimer s disease neuroimaging initiative adni']\n{'CSF', 'NIA', 'APOE', 'VBM', 'ADGC', 'GWAS', 'SNP', 'ROI', 'MAF', 'MRI', 'GLM', 'QTLs', 'PET', 'NIBIB', 'ROIs', 'FDR', 'ADNI', 'SNPs', 'ICV', 'MCI', 'FDA'}\n"
     ]
    }
   ],
   "source": [
    "doc_json = load_train_example_by_name(doc_id)\n",
    "\n",
    "doc_labels = list(metadata_train.loc[metadata_train.Id == doc_id, 'dataset_label'].values)\n",
    "doc_labels = [make_single_whitespace(remove_punc(l.strip())).lower() for l in doc_labels]\n",
    "doc_text = ' '.join([s['text'] for s in doc_json])\n",
    "print(doc_id)\n",
    "print(doc_labels)\n",
    "\n",
    "re_find_par = r'\\(([A-Z]{2,}-?[A-Z]{1,}?[a-z]?)[\\);]'\n",
    "matches = set(re.findall(re_find_par, doc_text))\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ratio has data: 1.0\nall has data: 12\nall: 21\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "in-wide target MRI imaging phenotypes from all baseline scans of ADNI participants as previously described (Risacher et al., 2009 ). First, voxel-based morphometry (VBM; Ashburner and Friston, 2000; Good et al., 2001; Mechelli et al., 2005) was performed to define global grey matter (GM) density maps and extract local GM density values for 86 target regions (Table 1) . Second, automated parcellation via FreeSurfer V4 (http://surfer.nmr.mgh.harvard.edu/) was conducted to define 56 volumetric and cortical thickness values (Table 2 ). All included ADNI participants had a minimum of two 1.5 T MP-RAGE scans at baseline following the ADNI MRI protocol (Jack et al., 2008) . Each raw scan was independently processed using FreeSurfer and VBM.\\nFor VBM analysis, SPM5 (http://www.fil.ion.ucl.ac.uk/spm/) was used to create an unmodulated normalized GM density map (1×1×1 mm voxel size, 10 mm FWHM Gaussian kernel for smoothing) in the MNI space for each scan as previously described (Risacher et al., 2009) . A mean GM density map was created as an average of two independent smoothed, unmodulated normalized GM density maps for each participant using SPM5. The MarsBaR region of interest (ROI) toolbox (Brett et al., 2002; Tzourio-Mazoyer et al., 2002 ) as implemented in SPM5 was then used to extract a single mean GM density value for 86 target regions in MNI space (Table 1) to be used as target QTs for the imaging genetic analyses. In addition to the individual MarsBaR ROIs, larger target regions defined by combining the mean GM density value from a set of MarsBaR ROIs were used as imaging phenotypes. All individual and combined mean GM density values are referred to as VBM phenotypes; see Table 1 for a total list and explanation of the 86 VBM phenotypes.\\nFor automated segmentation and parcellation, FreeSurfer V4 was employed to automatically label cortical and subcortical tissue classes using an atlas-based Bayesian segmentation procedure Fischl and Dale, 2000; Fischl et al., 2002 Fischl et al., , 1999 and to extract target region volume and cortical thickness, as well as to extract total intracranial volume (ICV) for all participants. Extracted FreeSurfer values for two independently processed MP-RAGE images of the same participant were averaged to create a mean value for volumetric and cortical thickness measures for all target regions. Mean volumetric and cortical thickness measures extracted using automated parcellation are referred to as FreeSurfer phenotypes; see Table 2 for a total list of the 56 FreeSurfer phenotypes defined for selected target regions.\\nGenome-wide association analysis of imaging phenotypes APOE genotype-The APOE gene is an important target gene in AD research (Farrer et al., 1997) . However, the two previously identified APOE SNPs important in AD susceptibility (rs429358, rs7412) were not available on the Illumina array. Therefore, we determined the genotypes of the two APOE SNPs (rs429358, rs7412) using the APOE ε2/ε3/ε4 status information from the ADNI clinical database for each participant.\\nQuality control-The original genotype data contained 620,903 markers, including 620,901 genomic markers on the Illumina chip plus 2 APOE SNPs whose values were obtained from the APOE status data. Only SNP markers were analyzed in this study. The following quality control (QC) steps were performed on these genotype data using the PLINK software package (http://pngu.mgh.harvard.edu/∼purcell/plink/), release v1.06. SNPs were excluded from the imaging genetics analysis if they could notmeet any of the following criteria: (1) call rate per SNP ≥90%, (2) minor allele frequency (MAF) ≥5%, and (3) Hardy-Weinberg equilibrium test of p≤10 −6 using healthy control (HC) subjects only. Participants were excluded from the analysis if any of the following criteria was not satisfied: (1) call rate per participant ≥90% (1 participant was excluded); (2) gender check (2 participants were excluded); and (3) identity check (3 sibling pairs were identified with PI_HAT over 0.5; one participant from each pair was randomly selected and excluded). Population stratification analysis suggested the advisability of restricting analyses to non-Hispanic Caucasians (79 participants were excluded from this report). After the QC procedure, 733 out of 818 participants and 530,992 out of 620,903 markers remained in the analysis and the overall genotyping rate for the remaining dataset was over 99.5%.\\nGWAS analyses-One hundred forty-two separate GWAS analyses on 142 selected imaging phenotypes (86 VBM phenotypes and 56 FreeSurfer phenotypes) were completed using the quality-controlled SNP data. All the imaging phenotypes were adjusted for the baseline age, gender, education, handedness, and baseline intracranial volume (ICV) using the regression weights derived from the HC participants, prior to any of the GWAS analyses (Risacher et al., 2009) . Using the PLINK software package (v1.06) with the quantitative trait association option, each GWAS analysis calculated the main effects of all SNPs on the target quantitative imaging phenotype. An additive SNP effect was assumed and the empirical p-values were based on the Wald statistic (Purcell et al., 2007) . Right hippocampal GM density was selected for a detailed sample analysis of a target QC because it had the largest number of associations at p<10 −6 . A Manhattan plot and a quantile-quantile (Q-Q) plot were used to visualize GWAS results for the right hippocampal GM density. All association results surviving the significance threshold of p<10 −6 were saved and prepared for additional pattern analysis.'},\n",
       " {'section_title': 'Sample characteristics after QC',\n",
       "  'text': 'After quality control of the genotyping data including the exclusion of 79 participants to avoid potential population stratification confounds, 733 out of 818 ADNI participants remained in the present study. Among these 733 participants, 729 sets of scans were successful in FreeSurfer segmentation and parcellation and were included in GWAS analyses of FreeSurfer phenotypes (56 volumetric and cortical thickness values described in Table 2 ). Seven hundred fifteen participants had successful VBM processing and were used in GWAS analyses of VBM phenotypes (86 GM density values described in Table 1 ). Table 3 shows the demographics information of the sample analyzed for both FreeSurfer and VBM studies. In both samples, gender and education are significantly different (overall p<0.05) among baseline diagnostic groups (HC, MCI, AD). In the subsequent GWAS analyses, baseline age and gender, as well as education, handedness, and baseline ICV are included as covariates.'},\n",
       " {'section_title': 'Methodological overview',\n",
       "  'text': 'Employing a whole genome and entire brain strategy, we presented an imaging genetics methodological framework for systematically identifying associations between genotypes and imaging phenotypes, and demonstrated the utility of this method using the ADNI cohort. Our imaging genetics method can be broadly summarized as the following four steps after quality control and preprocessing: (1) imaging phenotype definition, (2) GWAS of image phenotypes, (3) cluster and heat map analysis of imaging GWAS results, and (4) refined statistical modeling.\\nImaging phenotype definition-Eight-six GM density ROI measures and 56 volume and cortical thickness ROI measures were extracted, using VBM and FreeSurfer methods respectively, and analyzed as image phenotypes in independent GWAS analyses. This approach is complementary to another recently proposed imaging genetics analysis method, voxel-wise GWAS (vGWAS) (Stein et al., submitted for publication). The vGWAS technique explores SNP associations with all voxels in the image space. Our study is ROI-based, analyzing fewer but anatomically meaningful imaging phenotypes and thus, requires less computational resources. In addition, we used multiple techniques to define imaging phenotypes. Among the top 5 SNPs identified as part of the present study (Table 4) , rs10932886 (EPHA4), rs7610017 (TP63) and rs6463843 (NXPH1) are primarily associated with VBM QTs, rs2075650 (TOMM40) is associated with FreeSurfer QTs, and rs429358 (APOE) is associated with ROIs extracted using both techniques. These results suggest that the VBM and FreeSurfer QTs are not equally sensitive to the same genetic markers and consequently may provide complementary information. The VBM measures we employed are not modulated (Good et al., 2001 ) and therefore measure GM densities (Ashburner and Friston, 2000) , which are different from the volume and thickness measures that FreeSurfer generates for analysis. The complementary nature of GM density, volumetric, and cortical thickness ROIs in assessing of early AD, MCI, and pre-MCI samples is consistent with our recent findings examining ADNI baseline MRI data (Risacher et al., 2009 ) as well as an independent cohort .'},\n",
       " {'section_title': 'Limitations and future directions',\n",
       "  'text': 'The majority of analyses presented in this study focused on the extraction and evaluation of imaging phenotypes and the relationship of genetic variation to these phenotypes. However, we also included a limited assessment of the effects of baseline diagnostic group and the interaction effect of SNP and diagnosis in the analysis of candidate SNPs and phenotypes. Future studies could incorporate additional variables (e.g., clinical measures, other types of imaging and biomarkers) in the GWAS design to examine their effects and interactions with SNPs and/or target imaging phenotypes. The present analysis did not address epistasis or genegene interactions, a potentially very important topic. Future analyses should include models that incorporate epistatic interactions which are likely to be important for understanding susceptibility and protective factors in AD and other complex diseases.\\nAlthough we employed reasonably stringent thresholds for assessing genome-wide significance, a large number of ROIs represent a multiple comparison problem. The issue of determining the proper statistical threshold for a whole genome and whole brain search for associations is a challenging area for investigation (Nichols and Holmes, 2002; Nichols and Inkster, 2009; Stein et al., submitted for publication) . The issue is complicated by the fact that variables within both the genomic and neuroimaging dimensions are non-independent due to LD and spatial autocorrelation, respectively. The determination of the effective number of independent statistical tests under these conditions is an area of investigation. Models for the joint distribution of both dimensions under the null hypothesis require development and validation.\\nReplication of current and future GWAS results in independent samples will remain of critical importance for confirmation. Although our follow-up analyses examine additional statistics at a more detailed level for yielding additional insights, these statistics are non-independent of the statistics used to select candidate ROIs and candidate associations. Given the recent interest in the non-independent analysis issue (e.g., Kriegeskorte et al., 2009) , independent datasets for replication will be important for future studies to confirm the findings. For the current ADNI sample, given its modest size, we were unable to use one half of the data for hypothesis generation and the other half for confirmation, since one half of the data (i.e., n=367 in this study) cannot provide sufficient power to detect moderate/small genetic effects (Potkin et al., 2009b) . With additional replication and extension opportunities under development, we anticipate that there will be ample statistical power and the ability to replicate potentially important findings in multiple independent data sets in the future.\\nAt present there are few opportunities for replication of imaging genetics results such as those emerging from ADNI given the unique nature of this multi-dimensional data set. Fortunately, a worldwide ADNI consortium is actively being developed and large scale international data sets are likely to become available in the next few years that can provide adequate replication samples. In addition, the new NIH sponsored AD Genetics Consortium (ADGC) is assembling large meta-analytic databases of GWAS results that can provide confirmation of novel findings. Finally, the AlzGene meta-analytic database (www.alzgene.org) of candidate genes for AD, curated by Lars Bertram and colleagues (Bertram et al., 2007) , provides a regularly updated source for determining the replication and validation status of AD genes.\\nThe AAL atlas (Tzourio-Mazoyer et al., 2002) used to create the ROIs for the VBM analysis in this study is based on a single individual. To take anatomical variability into account, an important future direction will be to employ a probabilistic atlas, e.g., the Harvard-Oxford atlas (distributed with the FSL software package; http://fsl.fmrib.ox.ac.uk/fsl/), or the LONI probabilistic brain atlas (Shattuck et al., 2008) . The most appropriate method to derive a GMbased summary statistic (e.g., density or volume) for a probabilistic ROI is a topic warranting investigation.\\nDespite the limitations and challenges, the encouraging experimental results obtained using the proposed analytic framework appear to have substantial potential for enabling the discovery of imaging genetics associations and for localizing candidate imaging and genomic regions for refined statistical modeling and further characterization. Ultimately, imaging genetics holds the promise of providing important clues to pathophysiology that could inform development of methods for earlier detection and therapeutic intervention.\\nData analysis was supported in part by the following grants from the National Institutes of Health: NIA R01 AG19771 to A.J.S. and P30 AG10133 to Bernardino Ghetti, MD and NIBIB R03 EB008674 to L.S., by the Indiana Economic Development Corporation (IEDC 87884 to AJS), by Foundation for the NIH to A.J.S., and by an Indiana CTSI award to L.S.\\nThe FreeSurfer and PLINK analyses were performed on a 112-node parallel computing environment, called Quarry, at Indiana University. We thank the University Information Technology Services at Indiana University for their support.'},\n",
       " {'section_title': 'Fig. 1.',\n",
       "  'text': 'Heat maps of SNP associations with quantitative traits (QTs) at the significance level of p<10 −7 . GWAS results at a statistical threshold of p<10 −7 using QTs derived from FreeSurfer (top) and VBM/MarSBaR (bottom) are shown. −log 10 (p-values) from each GWAS are colormapped and displayed in the heat maps. Heat map blocks labeled with \"x\" reach the significance level of p<10 −7 . Only top SNPs and QTs are included in the heat maps, and so each row (SNP) and column (QT) has at least one \"x\" block. Dendrograms derived from hierarchical clustering are plotted for both SNPs and QTs. The color bar on the left side of the heat map codes the chromosome IDs for the corresponding SNPs. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Heat maps of SNP associations with quantitative traits (QTs) at the significance level of p<10 −6 . GWAS results at a statistical threshold of p<10 −6 using QTs derived from FreeSurfer (top) and VBM/MarSBaR (bottom) are shown. −log 10 (p-values) from each GWAS are colormapped and displayed in the heat maps. Heat map blocks labeled with \"x\" reach the significance level of p<10 −6 . Only top SNPs and QTs are included in the heat maps, and so each row (SNP) and column (QT) has at least one \"x\" block. Dendrograms derived from hierarchical clustering are plotted for both SNPs and QTs. The color bar on the left side of the heat map codes the chromosome IDs for the corresponding SNPs. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Manhattan and Q-Q plots of genome-wide association study (GWAS) of an example quantitative trait (QT). The QT examined in this analysis is the mean GM density of the right hippocampus (i.e., VBM phenotype RHippocampus, see Table 1 ) which was calculated using VBM/MarsBaR and adjusted for age, gender, education, handedness and ICV. Shown on the top panel is the Manhattan plot of the p-values (−log 10 (observed p-value)) from GWAS analysis of the QT. The horizontal lines display the cutoffs for two significant levels: blue line for p<10 −6 , and red line for p<10 −7 . Shown on the bottom panel is the quantile-quantile (Q-Q) plot of the distribution of the observed p-values (−log 10 (observed p-value)) in this sample versus the expected p-values (−log 10 (expected p-value)) under the null hypothesis of no association. Genomic inflation factor (based on median chi-squared) is 1.01667. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) VBM genetics analysis for rs6463843 (NXPH1). A two-way ANOVA was performed on mean GM density maps to compare rs6463843 SNP genotype and baseline diagnostic group within the ADNI cohort. Analysis of the contrast of two genotype groups, GG>TT, is shown (n=715; 166AD(44 TT, 78 GT, 44 GG); 346 MCI (82 TT, 170 GT, 94 GG); 203 HC (35 TT, 105 GT, 63 GG) ). Age, gender, education, handedness, and baseline ICV are included as covariates in all comparisons. Shown in the top panel (a) are the results of comparison involving all 715 subjects (i.e., across all the diagnostic groups), which are displayed at a threshold of p<0.01 (corrected with FDR) with minimum cluster size (k)=27. Shown in the bottom panel (b) are the results of comparisons within each of the three baseline diagnostic groups (AD, MCI, and Refined analysis of sample imaging phenotypes in relation to rs6463843 (NXPH1) and baseline diagnosis. Two-way ANOVAs were applied to examine the effects of rs6463843 (NXPH1) and baseline diagnosis on four target GM density measures: (a-b) left and right hippocampal GMDs, and (c-d) left and right mean medial temporal lobe GMDs. All the analyses included age, gender, education, handedness and baseline ICV as covariates. n=715 subjects were involved: 166 AD (44 TT, 78 GT, 44 GG); 346 MCI (82 TT, 170 GT, 94 GG); 203 HC (35 TT, 105 GT, 63 GG). The p-values for the main effect of diagnosis (DX), the main effect of SNP (SNP), and the interaction effect of SNP-by-diagnosis (DX×SNP) were shown in each plot. Table 1 VBM phenotypes defined as mean GM densities of various regions of interest (ROIs). SPM5 was applied for computing voxel-wise GM density values, while the MarsBaR ROI toolbox was used to define ROIs in the MNI space. A total number of 43 × 2 = 86 phenotypes were calculated. Each of the 43 IDs shown in the table corresponds to two phenotypes: one for the left side and the other for the right side. For example, \"LAmygdala\" indicates the mean GM density of the left amygdala. Each region marked with * in the table is a combined set of more than one MarsBaR ROI. For example, \"RMeanLatTemporal\" indicates the mean GM density of the right lateral temporal region defined by a set of MarsBaR ROIs, including right inferior temporal gyrus, right middle temporal gyrus, and right superior temporal gyrus. Table 3 Demographic information and total number of participants involved in each analysis. Of 818 ADNI participants, 733 remained after quality control of the genotyping data and consideration of population stratification. Among these 733 participants, 729 subjects succeeded in FreeSurfer segmentation and parcellation and were involved in the GWAS analysis of FreeSurfer phenotypes. Of these, 715 subjects had successful VBM processing and were involved in the GWAS analysis of VBM phenotypes. Basic demographics information is shown for both groups of participants. Neuroimage. Author manuscript; available in PMC 2010 November 1.'}]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "l_search = doc_labels[0]\n",
    "secs_with_label = [section for section in doc_json if l_search in clean_text(section['text'])]\n",
    "\n",
    "has_kw = 0\n",
    "has_kw_all = 0\n",
    "for sec in secs_with_label:\n",
    "    if 'data' in clean_text(sec['text']):\n",
    "        has_kw += 1\n",
    "\n",
    "for sec in doc_json:\n",
    "    if 'data' in clean_text(sec['text']):\n",
    "        has_kw_all += 1\n",
    "\n",
    "print(f'ratio has data: {has_kw / len(secs_with_label)}')\n",
    "print(f'all has data: {has_kw_all}')\n",
    "print(f'all: {len(doc_json)}')\n",
    "secs_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['the most recent collisions.',\n",
       " 'We used the 2006 Coastal Change Analysis Program for San Clemente Island, CA and western Maine to describe the land cover and land use (National Oceanic and Atmospheric Administration Coastal Services Center 2012).',\n",
       " 'We used the 2001 National Land Cover Database for Onondaga County, NY (Homer et al.',\n",
       " '2007 ).',\n",
       " 'Land-cover and land-use maps were base']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "sent_tokenize('the most recent collisions.\\nWe used the 2006 Coastal Change Analysis Program for San Clemente Island, CA and western Maine to describe the land cover and land use (National Oceanic and Atmospheric Administration Coastal Services Center 2012). We used the 2001 National Land Cover Database for Onondaga County, NY (Homer et al. 2007 ). Land-cover and land-use maps were base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEFTs : Tokens ['the', 'design', 'effects'] do not make a dataset name.\nDEFTs : Aftertoken for was in banlist.\nPSEFIRTY : Tokens ['consider', 'type', 'of', 'institution', 'first', 'attended'] do not make a dataset name.\nPSEFIRDA : Tokens ['education', 'enrollment', 'date', 'for', 'valid', 'institutions'] do not make a dataset name.\nBPSLNKWT : Tokens ['This', 'disturbance', 'term', 'inflated', 'the', 'weight'] do not make a dataset name.\nBPSLNKWT : Aftertoken so was in banlist.\nDEFT : Tokens ['dependent', 'variable'] do not make a dataset name.\nSES : Tokens ['status'] do not make a dataset name.\nSES : Aftertoken are was in banlist.\nBYSES : Tokens ['1.', 'Low', 'SES'] do not make a dataset name.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'NEB': ('Beginning Postsecondary Longitudinal Study', 'Data'),\n",
       " 'PSE': ('Postsecondary Education', 'enrollment.'),\n",
       " 'BYFCOMP': ('Low SES BYSES 2. Single parent family', '3.'),\n",
       " 'ANOVA': ('Analysis of Variance', 'was'),\n",
       " 'GED': ('General Educational Development', ','),\n",
       " 'DAS': ('Data File Data Analysis System', 'see'),\n",
       " 'IPEDS': ('Integrated Postsecondary Education Data System', 'data')}"
      ]
     },
     "metadata": {},
     "execution_count": 599
    }
   ],
   "source": [
    "selected_mathces = {}\n",
    "for m in matches:\n",
    "    try:\n",
    "        before_tokens, found_tokens, after_token = get_words_from_abbr_in_parantheses(m, doc_text)\n",
    "    except Exception as e:\n",
    "        print(f'Exception for {m}')\n",
    "        raise e\n",
    "\n",
    "    cond1 = tokens_are_dataset_name(found_tokens)\n",
    "    cond2 = after_token_ok(after_token)\n",
    "    cond3 = before_tokens_ok(before_tokens)\n",
    "\n",
    "    if not cond1:\n",
    "        print(f'{m} : Tokens {found_tokens} do not make a dataset name.')\n",
    "\n",
    "    if not cond2:\n",
    "        print(f'{m} : Aftertoken {after_token} was in banlist.')\n",
    "\n",
    "    if not cond3:\n",
    "        print(f'{m} : Beforetokens {before_tokens} were in banlist.')\n",
    "\n",
    "    if cond1 and cond2 and cond3:\n",
    "        selected_mathces[m] = (' '.join(found_tokens), after_token)\n",
    "\n",
    "selected_mathces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'NEB': ('Beginning Postsecondary Longitudinal Study', 'Data'),\n",
       " 'PSE': ('Postsecondary Education', 'enrollment.'),\n",
       " 'BYFCOMP': ('Low SES BYSES 2. Single parent family', '3.'),\n",
       " 'ANOVA': ('Analysis of Variance', 'was'),\n",
       " 'GED': ('General Educational Development', ','),\n",
       " 'DAS': ('Data File Data Analysis System', 'see'),\n",
       " 'IPEDS': ('Integrated Postsecondary Education Data System', 'data')}"
      ]
     },
     "metadata": {},
     "execution_count": 600
    }
   ],
   "source": [
    "# Drop by keyword\n",
    "matches_not_banned = {m: v for m, v in selected_mathces.items() if m not in banned_kw}\n",
    "matches_not_banned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'NEB': ('Beginning Postsecondary Longitudinal Study', 'Data'),\n",
       " 'PSE': ('Postsecondary Education', 'enrollment.'),\n",
       " 'BYFCOMP': ('Low SES BYSES 2. Single parent family', '3.'),\n",
       " 'GED': ('General Educational Development', ','),\n",
       " 'IPEDS': ('Integrated Postsecondary Education Data System', 'data')}"
      ]
     },
     "metadata": {},
     "execution_count": 601
    }
   ],
   "source": [
    "# Drop by text\n",
    "matches_not_banned = {m: v for m, v in matches_not_banned.items() if not any([b for b in banned_values if b in v[0].lower()])}\n",
    "matches_not_banned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ECLS-K', 'IEP', 'IRT', 'MD', 'NCES', 'SEM', 'SES'}"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": []
  },
  {
   "source": [
    "clues:\n",
    "- between parantheses\n",
    "- starts with such as\n",
    "- has abbreviation between parantheses\n",
    "- starts with capital letters or all capital letters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "How to process:\n",
    "\n",
    "Split into sentences\n",
    "\n",
    "Keep uppercase letters.\n",
    "\n",
    "remove []\n",
    "\n",
    "keep ()\n",
    "\n",
    "Capital letter words followed by (abbreviation)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ]
}