{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd001de0ae40aa8a02f5dce4eb302558c2ba1e499509f0a7c12e0772621a5681a06",
   "display_name": "Python 3.7.8 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train size: 15728\nval size: 3933\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_example_paths = glob.glob('data/train/*.json')\n",
    "test_example_paths = glob.glob('data/test/*.json')\n",
    "\n",
    "train_example_names = [fn.split('.')[0] for fn in os.listdir('data/train')]\n",
    "test_example_names = [fn.split('.')[0] for fn in os.listdir('data/test')]\n",
    "\n",
    "metadata = pd.read_csv('data/train.csv')\n",
    "metadata_train = metadata.loc[metadata.Id.isin(train_example_names)]\n",
    "metadata_test = metadata.loc[metadata.Id.isin(test_example_names)]\n",
    "\n",
    "import random\n",
    "\n",
    "docIdx = metadata_train.Id.values.copy()\n",
    "random.seed(42)\n",
    "random.shuffle(docIdx)\n",
    "\n",
    "train_ratio = 0.8\n",
    "n_train = int(len(docIdx) * train_ratio)\n",
    "n_val = len(docIdx) - n_train\n",
    "\n",
    "train_idx = docIdx[:n_train]\n",
    "val_idx = docIdx[n_train:]\n",
    "\n",
    "print(f'train size: {len(train_idx)}')\n",
    "print(f'val size: {len(val_idx)}')"
   ]
  },
  {
   "source": [
    "### Utils"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_example_by_name(name):\n",
    "    doc_path = os.path.join('data/test', name + '.json')\n",
    "    with open(doc_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_train_example_by_name(name):\n",
    "    doc_path = os.path.join('data/train', name + '.json')\n",
    "    with open(doc_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def delete_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "source": [
    "### Feature Extraction Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "\n",
    "def get_features(s):\n",
    "    return [(w, t) for w, t in zip(\\\n",
    "            s['TOKEN'].values.tolist(),\n",
    "            s['TARGET'].values.tolist()                          \n",
    "        )]\n",
    "\n",
    "import string\n",
    "puncs = [c for c in string.punctuation]\n",
    "\n",
    "def mask_numbers(text):\n",
    "        # Replace each numeric char with '#'\n",
    "        \n",
    "        def repl(m):\n",
    "            return f\" {'#' * len(m.group())} \"\n",
    "        text = re.sub(r'[0-9]+', repl, text)\n",
    "        return text\n",
    "\n",
    "def make_single_whitespace(text):\n",
    "    return _RE_COMBINE_WHITESPACE.sub(\" \", text).strip()\n",
    "\n",
    "class TextFeatureExtractor:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Initialize super\n",
    "        \n",
    "        # Load parameters\n",
    "        def_args = dict()\n",
    "        \n",
    "        # Extract related arguments\n",
    "        for k, def_val in def_args.items():\n",
    "            self.__dict__.update({k: kwargs.get(k, def_val)})\n",
    "\n",
    "    def transform(self, x):\n",
    "        x.update({'output': [_df2features(x['output'])]})\n",
    "        return x\n",
    "\n",
    "    def _mask_numbers(self, text):\n",
    "        # Replace each numeric char with #\n",
    "        \n",
    "        def repl(m):\n",
    "            return f\" {'#' * len(m.group())} \"\n",
    "        text = re.sub(r'[0-9]+', repl, text)\n",
    "        return text\n",
    "\n",
    "    def fit_transform(self, data, train_filenames, val_filenames):\n",
    "        self.train_filenames = train_filenames\n",
    "        self.val_filenames = val_filenames\n",
    "\n",
    "        \n",
    "        output = {}\n",
    "\n",
    "        # Process each set\n",
    "        for setname in ['train', 'val']:\n",
    "            docs = []\n",
    "            for f in tqdm(self.__dict__.get(f'{setname}_filenames')):\n",
    "                df_slice = data[f]\n",
    "\n",
    "                assert not df_slice['TOKEN'].isnull().any(), 'All tokens must have a value'\n",
    "                df_slice['TARGET'] = df_slice['TARGET'].fillna('OTHER')\n",
    "                df_slice['TOKEN'] = df_slice['TOKEN'].values.astype('U')\n",
    "                df_slice['TOKEN'] = df_slice['TOKEN'].apply(mask_numbers)\n",
    "                df_slice['TOKEN'] = df_slice['TOKEN'].apply(make_single_whitespace)\n",
    "\n",
    "                data_slice = get_features(df_slice)\n",
    "                docs.append(data_slice)\n",
    "            \n",
    "            X = [_doc2features(s) for s in tqdm(docs)]\n",
    "            y = [_doc2labels(s) for s in tqdm(docs)]\n",
    "\n",
    "            del docs\n",
    "            \n",
    "            assert(len(X) == len(y))\n",
    "            \n",
    "            output[f'{setname}_data'] = (X, y)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class DocGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_doc = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(\\\n",
    "            s['TOKEN'].values.tolist(), \n",
    "            s['TARGET'].values.tolist()\n",
    "                                                                     \n",
    "        )]\n",
    "        self.grouped = self.data.groupby('FILENAME').apply(agg_func)\n",
    "        self.docs = [s for s in self.grouped]\n",
    "\n",
    "def _text2features(text):\n",
    "    \"\"\"Returns a list of examples.\n",
    "    \"\"\"\n",
    "    #words = wordpunct_tokenize(text)\n",
    "    return [_word2features(words, i) for i in range(len(words))]\n",
    "\n",
    "def _df2features(df):\n",
    "    \"\"\"Returns a list of examples.\n",
    "    \"\"\"\n",
    "    for col in ['TOKEN']:\n",
    "        assert(col in df.columns)\n",
    "    \n",
    "    df['TOKEN'] = df['TOKEN'].values.astype('U')\n",
    "    df['TOKEN'] = df['TOKEN'].apply(mask_numbers)\n",
    "    df['TOKEN'] = df['TOKEN'].apply(make_single_whitespace)\n",
    "    \n",
    "    agg_func = lambda s: [(w,) for w in s['TOKEN'].values.tolist()]\n",
    "    feature_list = agg_func(df)\n",
    "    words = [s for s in feature_list]\n",
    "    \n",
    "    return _doc2features(words)\n",
    "\n",
    "def _word2features(words, i):\n",
    "    word = words[i]\n",
    "    if not isinstance(word, str):\n",
    "        word = word[0]\n",
    "    \n",
    "    # isfirstname = fe_isname.is_firstname(word)\n",
    "    # islastname = fe_isname.is_lastname(word)\n",
    "    # isname = isfirstname or islastname\n",
    "    \n",
    "    # if isfirstname and islastname:\n",
    "    #     word = '#NAME#'\n",
    "    # elif isfirstname:\n",
    "    #     word = '#FIRSTNAME#'\n",
    "    # elif islastname:\n",
    "    #     word = '#LASTNAME#'\n",
    "\n",
    "    digit_count = sum(c=='#' for c in word)\n",
    "    length = len(word)\n",
    "    assert length > 0, \"All tokens must have length > 0\"\n",
    "\n",
    "    features = {\n",
    "        #'bias': 1.0,\n",
    "        #'word.index': i\n",
    "    }\n",
    "    \n",
    "    # Add line & word indices\n",
    "    # features.update({\n",
    "    #     'word.lineindex': li,\n",
    "    #     'word.wordindex': wi,\n",
    "        \n",
    "    # })\n",
    "    \n",
    "    # if isname:\n",
    "    #     features.update({\n",
    "    #     'word.lower()': word\n",
    "        \n",
    "    # })\n",
    "    #else:\n",
    "    # If all digits\n",
    "    if word.isdigit():\n",
    "        features.update({\n",
    "            'isd': True,\n",
    "            'dct': digit_count,\n",
    "            '4dg': digit_count == 4,\n",
    "            'dgr': 1.0,\n",
    "            'len': length\n",
    "        })\n",
    "    else: # Not all digit\n",
    "        features.update({\n",
    "            'isd': False,\n",
    "            'dgr': digit_count / length,\n",
    "            'dct': digit_count,\n",
    "            'len': length,\n",
    "            'wor': word\n",
    "        })#'pnc': np.mean(np.array([c in puncs for c in word]))\n",
    "\n",
    "    if i > 0:\n",
    "        word_other = words[i-1][0]\n",
    "        features.update({\n",
    "            '-1': word_other,\n",
    "            #'-1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "        if i > 1:\n",
    "            word_other = words[i-2][0]\n",
    "            features.update({\n",
    "                '-2': word_other,\n",
    "                #'-2:word.isupper()': word2.isupper()\n",
    "            })\n",
    "            if i > 2:\n",
    "                word_other = words[i-3][0]\n",
    "                features.update({\n",
    "                    '-3': word_other,\n",
    "                    #'-3:word.isupper()': word_other.isupper()\n",
    "                })\n",
    "                if i > 3:\n",
    "                    word_other = words[i-4][0]\n",
    "                    features.update({\n",
    "                        '-4': word_other,\n",
    "                        #'-4:word.isupper()': word_other.isupper()\n",
    "                    })\n",
    "                    if i > 4:\n",
    "                        word_other = words[i-5][0]\n",
    "                        features.update({\n",
    "                            '-5': word_other\n",
    "                        })\n",
    "                        if i > 5:\n",
    "                            word_other = words[i-6][0]\n",
    "                            features.update({\n",
    "                                '-6': word_other\n",
    "                            })\n",
    "                            \n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(words)-1:\n",
    "        word_other = words[i+1][0]\n",
    "        features.update({\n",
    "            '+1':  word_other,\n",
    "            #'+1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "        if i < len(words)-2:\n",
    "            word_other = words[i+2][0]\n",
    "            features.update({\n",
    "                '+2':  word_other,\n",
    "                #'+2:word.isupper()': word2.isupper()\n",
    "            })\n",
    "            if i < len(words)-3:\n",
    "                word_other = words[i+3][0]\n",
    "                features.update({\n",
    "                    '+3':  word_other,\n",
    "                    #'+3:word.isupper()': word_other.isupper()\n",
    "                })\n",
    "                \n",
    "                if i < len(words)-4:\n",
    "                    word_other = words[i+4][0]\n",
    "                    features.update({\n",
    "                        '+4':  word_other,\n",
    "                        #'+4:word.isupper()': word_other.isupper()\n",
    "                    })\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features\n",
    "\n",
    "def _doc2features(doc):\n",
    "    \"\"\"Returns a list of examples.\n",
    "    \"\"\"\n",
    "    words = [(ex[0],) for ex in doc]\n",
    "    return [_word2features(words, i) for i in range(len(words))]\n",
    "\n",
    "def _doc2labels(doc):\n",
    "    return [s[-1] for s in doc]\n",
    "def _doc2tokens(doc):\n",
    "    return [s[0] for s in doc]"
   ]
  },
  {
   "source": [
    "### Preprocessing Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokenize_doc(doc_json):\n",
    "    doc_text = ' '.join([clean_text(sec['text']) for sec in doc])\n",
    "    doc_text = make_single_whitespace(doc_text)\n",
    "\n",
    "    doc_tokens = doc_text.split(' ')\n",
    "    return doc_tokens\n",
    "\n",
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())"
   ]
  },
  {
   "source": [
    "### Load Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load('pipeline_model.joblib')"
   ]
  },
  {
   "source": [
    "### Create Submission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = TextFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "ids = []\n",
    "labels = []\n",
    "for test_id in val_idx[:50]:\n",
    "    \n",
    "    # Load and preprocess\n",
    "    doc = load_train_example_by_name(test_id)\n",
    "    doc_tokens = preprocess_tokenize_doc(doc)\n",
    "\n",
    "    # Extract features\n",
    "    x = {'output': pd.DataFrame({'TOKEN': doc_tokens})}\n",
    "    x = feature_extractor.transform(x)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(x['output'])\n",
    "    pred = pred[0]\n",
    "    pred = np.array([int(p) for p in pred])\n",
    "\n",
    "    # Get corresponding tokens\n",
    "    pos_pred_idx = [i[0] for i in np.argwhere(pred == 1)]\n",
    "    pred_tokens = [doc_tokens[i] for i in pos_pred_idx]\n",
    "\n",
    "    pred_joined = ' '.join(pred_tokens)\n",
    "\n",
    "    test_preds.append(pred_joined)\n",
    "    ids.append(test_id)\n",
    "    labels.append(metadata_train.loc[metadata_train.Id == test_id, 'cleaned_label'].values[0])\n",
    "\n",
    "sub_df = pd.DataFrame(columns = ['Id', 'PredictionString'])\n",
    "sub_df['Id'] = ids\n",
    "sub_df['PredictionString'] = test_preds\n",
    "sub_df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      Id  \\\n",
       "0   fdd86521-c308-42ef-8b05-70de53090360   \n",
       "1   3d3a2806-1f3d-4ac6-a288-32357eaa95e6   \n",
       "2   c29ff858-294a-47e4-81e3-9932d30aa321   \n",
       "3   16fdb856-59ea-4dce-aa61-e6b450aca460   \n",
       "4   0c847fd4-5031-4702-9a11-07529cef899f   \n",
       "5   bc0c96ef-7f58-4004-8615-6e5f5782af94   \n",
       "6   158d788c-e67b-4dda-bbd1-80fb8f938ccf   \n",
       "7   29894d91-12ad-4999-9e32-091a92726df5   \n",
       "8   f70051bf-a763-415b-aa66-97ae57f2efc1   \n",
       "9   f4e954ad-15be-4b9d-858a-9679eedf7cd0   \n",
       "10  9fb3e932-6d8a-47e4-8319-6f98820453f8   \n",
       "11  5788234c-0d75-4ba2-a197-2be322ed1e82   \n",
       "12  94b7948f-6578-44a5-b09b-96f4c2457d0a   \n",
       "13  67c5e3fa-867a-4847-aa80-9f7f92382c15   \n",
       "14  de9ba65d-7a3e-4a5d-8096-696c97c22bb0   \n",
       "15  deba1f17-9fe6-4103-82ae-6ed3127d453e   \n",
       "16  2ef5872b-b48c-4299-8329-945a3cae90b4   \n",
       "17  008cbc40-26c1-489a-942f-67b5ded190c2   \n",
       "18  200ab990-48ef-4b85-b268-755ef01af922   \n",
       "19  afd88d32-1445-40b3-aac7-91cfaea120a2   \n",
       "20  66e0426b-6afb-4c59-961a-ecdf8acd8812   \n",
       "21  7d5d7fa9-7c79-4a57-9de2-fda28a0d8640   \n",
       "22  09608747-49bf-49dc-8a7c-7b068b463e77   \n",
       "23  d6d0fbfb-63f1-4380-8b4a-85139620b08f   \n",
       "24  80fc9c0c-d478-46b0-b419-d572124129a6   \n",
       "25  94425568-18e3-47f2-ad18-a34c2bf0298e   \n",
       "26  b8e62fc3-3c10-421c-826d-bf540038e554   \n",
       "27  fd2d97bd-4a65-40ef-bc4a-a52c504e054e   \n",
       "28  cd0c8102-1db6-4b46-996c-e3fe6395aa50   \n",
       "29  5525474a-b40e-4411-8ba4-acb595c3bd4e   \n",
       "30  3ba07713-d297-420a-b8d0-035806da1923   \n",
       "31  b34d801d-7d43-4266-b642-683a8031915a   \n",
       "32  1126d384-a39e-4e9a-9570-d11df665f77e   \n",
       "33  3ee830ad-2ec8-42c3-aeaa-eef2e4f38d02   \n",
       "34  ca66cfac-6db0-4901-9944-4e193e4bdd38   \n",
       "35  5dc196d2-9ebd-4e09-82ff-b90e6c70167e   \n",
       "36  550ea55c-6e6d-4dbb-8736-fb497c4234d9   \n",
       "37  6299b74c-f0ac-47c0-8dad-af9c1c5debb7   \n",
       "38  da3620d4-9d47-4a28-9a92-bfe99cc1226b   \n",
       "39  6348404c-81b2-4bb2-8a55-6a8f9880725f   \n",
       "40  e84aa6b5-3e1e-4c6c-a2b9-350f72ac8a43   \n",
       "41  26e197c6-c524-4a74-aa26-67396856638d   \n",
       "42  ab215b47-e85d-4a44-9ae7-04e9627683db   \n",
       "43  bc1b57f7-2449-4b43-afda-ab79cf28dcbf   \n",
       "44  e43f96ad-c523-4b18-99c9-7b87906a734d   \n",
       "45  7b050556-5a7a-4572-9f62-c480bee6a3cb   \n",
       "46  2a8a1b39-4c3c-435f-9d4b-5e855a5c18cf   \n",
       "47  e0d7661e-c5d0-4ec6-923e-c3e694baaddc   \n",
       "48  2f3abc7c-408e-4893-a5c2-108afbe7cca9   \n",
       "49  8b79b4ad-5c8b-4eb5-9d1b-77ffac06615c   \n",
       "\n",
       "                                     PredictionString  \\\n",
       "0   coastal change analysis program coastal change...   \n",
       "1                                             ibtracs   \n",
       "2   the alzheimer s disease neuroimaging initiativ...   \n",
       "3   the alzheimer s disease neuroimaging initiativ...   \n",
       "4                usda rural urban continuum codes the   \n",
       "5                                                       \n",
       "6   the national education longitudinal study of n...   \n",
       "7      the north american breeding bird survey bbs in   \n",
       "8   mllw tidal level at noaa tidal station noaa ti...   \n",
       "9   the early childhood longitudinal study timss t...   \n",
       "10  any sequence of dsdna progress in sars cov 2 g...   \n",
       "11              national education longitudinal study   \n",
       "12                                common core of data   \n",
       "13                                     adni adni adni   \n",
       "14  census of agriculture census of agriculture ce...   \n",
       "15  the national education longitudinal survey the...   \n",
       "16  els national education longitudinal study bacc...   \n",
       "17                                               adni   \n",
       "18  the rural urban continuum code rural urban con...   \n",
       "19  covid 19 deaths per covid 19 deaths in covid 1...   \n",
       "20  the alzheimer s disease neuroimaging initiativ...   \n",
       "21          the baltimore longitudinal study of aging   \n",
       "22       the national education longitudinal study of   \n",
       "23  of alzheimer s disease neuroimaging initiative...   \n",
       "24  18 221 whole genome sequence of sars cov 2 who...   \n",
       "25                                                      \n",
       "26  educational longitudinal study the early child...   \n",
       "27        the agricultural resource management survey   \n",
       "28  cohort alzheimer s disease neuroimaging initia...   \n",
       "29  the trends in international mathematics and sc...   \n",
       "30  of alzheimer s disease neuroimaging initiative...   \n",
       "31          the baltimore longitudinal study of aging   \n",
       "32  ibtracs ibtracs ibtracs ibtracs ibtracs ibtrac...   \n",
       "33  beginning postsecondary students national post...   \n",
       "34             the early childhood longitudinal study   \n",
       "35  beginning postsecondary student beginning post...   \n",
       "36  genome sequence of 2019 ncov the genome sequen...   \n",
       "37          the baltimore longitudinal study of aging   \n",
       "38             the early childhood longitudinal study   \n",
       "39  the alzheimer s disease neuroimaging initiativ...   \n",
       "40      ongoing baltimore longitudinal study of aging   \n",
       "41                        survey of earned doctorates   \n",
       "42  the high school longitudinal study of the high...   \n",
       "43  the alzheimer s disease neuroimaging initiativ...   \n",
       "44                                  our world in data   \n",
       "45  timss trends in international mathematics and ...   \n",
       "46                       education longitudinal study   \n",
       "47          the baltimore longitudinal study of aging   \n",
       "48  the alzheimer s disease neuroimaging initiativ...   \n",
       "49  from alzheimer s disease neuroimaging initiati...   \n",
       "\n",
       "                                               labels  \n",
       "0                     coastal change analysis program  \n",
       "1                                             ibtracs  \n",
       "2                                                adni  \n",
       "3                                                adni  \n",
       "4                         rural urban continuum codes  \n",
       "5   international best track archive for climate s...  \n",
       "6               national education longitudinal study  \n",
       "7            north american breeding bird survey bbs   \n",
       "8                                  noaa tidal station  \n",
       "9                  early childhood longitudinal study  \n",
       "10                        sars cov 2 genome sequences  \n",
       "11                       education longitudinal study  \n",
       "12  national center for education statistics commo...  \n",
       "13                                               adni  \n",
       "14            agricultural resource management survey  \n",
       "15              national education longitudinal study  \n",
       "16        baccalaureate and beyond longitudinal study  \n",
       "17                                               adni  \n",
       "18                        rural urban continuum codes  \n",
       "19                                  our world in data  \n",
       "20                                               adni  \n",
       "21        baltimore longitudinal study of aging blsa   \n",
       "22              national education longitudinal study  \n",
       "23                                               adni  \n",
       "24                     genome sequences of sars cov 2  \n",
       "25                                               adni  \n",
       "26                 early childhood longitudinal study  \n",
       "27            agricultural resource management survey  \n",
       "28                                               adni  \n",
       "29  trends in international mathematics and scienc...  \n",
       "30                                               adni  \n",
       "31              baltimore longitudinal study of aging  \n",
       "32  international best track archive for climate s...  \n",
       "33  beginning postsecondary students longitudinal ...  \n",
       "34                 early childhood longitudinal study  \n",
       "35  beginning postsecondary students longitudinal ...  \n",
       "36                          2019 ncov genome sequence  \n",
       "37              baltimore longitudinal study of aging  \n",
       "38                 early childhood longitudinal study  \n",
       "39                                               adni  \n",
       "40        baltimore longitudinal study of aging blsa   \n",
       "41                        survey of earned doctorates  \n",
       "42                     high school longitudinal study  \n",
       "43                                               adni  \n",
       "44                                  our world in data  \n",
       "45  trends in international mathematics and scienc...  \n",
       "46              national education longitudinal study  \n",
       "47        baltimore longitudinal study of aging blsa   \n",
       "48                                               adni  \n",
       "49                                               adni  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>PredictionString</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fdd86521-c308-42ef-8b05-70de53090360</td>\n      <td>coastal change analysis program coastal change...</td>\n      <td>coastal change analysis program</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3d3a2806-1f3d-4ac6-a288-32357eaa95e6</td>\n      <td>ibtracs</td>\n      <td>ibtracs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c29ff858-294a-47e4-81e3-9932d30aa321</td>\n      <td>the alzheimer s disease neuroimaging initiativ...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16fdb856-59ea-4dce-aa61-e6b450aca460</td>\n      <td>the alzheimer s disease neuroimaging initiativ...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0c847fd4-5031-4702-9a11-07529cef899f</td>\n      <td>usda rural urban continuum codes the</td>\n      <td>rural urban continuum codes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bc0c96ef-7f58-4004-8615-6e5f5782af94</td>\n      <td></td>\n      <td>international best track archive for climate s...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>158d788c-e67b-4dda-bbd1-80fb8f938ccf</td>\n      <td>the national education longitudinal study of n...</td>\n      <td>national education longitudinal study</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>29894d91-12ad-4999-9e32-091a92726df5</td>\n      <td>the north american breeding bird survey bbs in</td>\n      <td>north american breeding bird survey bbs</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>f70051bf-a763-415b-aa66-97ae57f2efc1</td>\n      <td>mllw tidal level at noaa tidal station noaa ti...</td>\n      <td>noaa tidal station</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>f4e954ad-15be-4b9d-858a-9679eedf7cd0</td>\n      <td>the early childhood longitudinal study timss t...</td>\n      <td>early childhood longitudinal study</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9fb3e932-6d8a-47e4-8319-6f98820453f8</td>\n      <td>any sequence of dsdna progress in sars cov 2 g...</td>\n      <td>sars cov 2 genome sequences</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5788234c-0d75-4ba2-a197-2be322ed1e82</td>\n      <td>national education longitudinal study</td>\n      <td>education longitudinal study</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>94b7948f-6578-44a5-b09b-96f4c2457d0a</td>\n      <td>common core of data</td>\n      <td>national center for education statistics commo...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>67c5e3fa-867a-4847-aa80-9f7f92382c15</td>\n      <td>adni adni adni</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>de9ba65d-7a3e-4a5d-8096-696c97c22bb0</td>\n      <td>census of agriculture census of agriculture ce...</td>\n      <td>agricultural resource management survey</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>deba1f17-9fe6-4103-82ae-6ed3127d453e</td>\n      <td>the national education longitudinal survey the...</td>\n      <td>national education longitudinal study</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2ef5872b-b48c-4299-8329-945a3cae90b4</td>\n      <td>els national education longitudinal study bacc...</td>\n      <td>baccalaureate and beyond longitudinal study</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>008cbc40-26c1-489a-942f-67b5ded190c2</td>\n      <td>adni</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>200ab990-48ef-4b85-b268-755ef01af922</td>\n      <td>the rural urban continuum code rural urban con...</td>\n      <td>rural urban continuum codes</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>afd88d32-1445-40b3-aac7-91cfaea120a2</td>\n      <td>covid 19 deaths per covid 19 deaths in covid 1...</td>\n      <td>our world in data</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>66e0426b-6afb-4c59-961a-ecdf8acd8812</td>\n      <td>the alzheimer s disease neuroimaging initiativ...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>7d5d7fa9-7c79-4a57-9de2-fda28a0d8640</td>\n      <td>the baltimore longitudinal study of aging</td>\n      <td>baltimore longitudinal study of aging blsa</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>09608747-49bf-49dc-8a7c-7b068b463e77</td>\n      <td>the national education longitudinal study of</td>\n      <td>national education longitudinal study</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>d6d0fbfb-63f1-4380-8b4a-85139620b08f</td>\n      <td>of alzheimer s disease neuroimaging initiative...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>80fc9c0c-d478-46b0-b419-d572124129a6</td>\n      <td>18 221 whole genome sequence of sars cov 2 who...</td>\n      <td>genome sequences of sars cov 2</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>94425568-18e3-47f2-ad18-a34c2bf0298e</td>\n      <td></td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>b8e62fc3-3c10-421c-826d-bf540038e554</td>\n      <td>educational longitudinal study the early child...</td>\n      <td>early childhood longitudinal study</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>fd2d97bd-4a65-40ef-bc4a-a52c504e054e</td>\n      <td>the agricultural resource management survey</td>\n      <td>agricultural resource management survey</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>cd0c8102-1db6-4b46-996c-e3fe6395aa50</td>\n      <td>cohort alzheimer s disease neuroimaging initia...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>5525474a-b40e-4411-8ba4-acb595c3bd4e</td>\n      <td>the trends in international mathematics and sc...</td>\n      <td>trends in international mathematics and scienc...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>3ba07713-d297-420a-b8d0-035806da1923</td>\n      <td>of alzheimer s disease neuroimaging initiative...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>b34d801d-7d43-4266-b642-683a8031915a</td>\n      <td>the baltimore longitudinal study of aging</td>\n      <td>baltimore longitudinal study of aging</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>1126d384-a39e-4e9a-9570-d11df665f77e</td>\n      <td>ibtracs ibtracs ibtracs ibtracs ibtracs ibtrac...</td>\n      <td>international best track archive for climate s...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>3ee830ad-2ec8-42c3-aeaa-eef2e4f38d02</td>\n      <td>beginning postsecondary students national post...</td>\n      <td>beginning postsecondary students longitudinal ...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>ca66cfac-6db0-4901-9944-4e193e4bdd38</td>\n      <td>the early childhood longitudinal study</td>\n      <td>early childhood longitudinal study</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>5dc196d2-9ebd-4e09-82ff-b90e6c70167e</td>\n      <td>beginning postsecondary student beginning post...</td>\n      <td>beginning postsecondary students longitudinal ...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>550ea55c-6e6d-4dbb-8736-fb497c4234d9</td>\n      <td>genome sequence of 2019 ncov the genome sequen...</td>\n      <td>2019 ncov genome sequence</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>6299b74c-f0ac-47c0-8dad-af9c1c5debb7</td>\n      <td>the baltimore longitudinal study of aging</td>\n      <td>baltimore longitudinal study of aging</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>da3620d4-9d47-4a28-9a92-bfe99cc1226b</td>\n      <td>the early childhood longitudinal study</td>\n      <td>early childhood longitudinal study</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>6348404c-81b2-4bb2-8a55-6a8f9880725f</td>\n      <td>the alzheimer s disease neuroimaging initiativ...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>e84aa6b5-3e1e-4c6c-a2b9-350f72ac8a43</td>\n      <td>ongoing baltimore longitudinal study of aging</td>\n      <td>baltimore longitudinal study of aging blsa</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>26e197c6-c524-4a74-aa26-67396856638d</td>\n      <td>survey of earned doctorates</td>\n      <td>survey of earned doctorates</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>ab215b47-e85d-4a44-9ae7-04e9627683db</td>\n      <td>the high school longitudinal study of the high...</td>\n      <td>high school longitudinal study</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>bc1b57f7-2449-4b43-afda-ab79cf28dcbf</td>\n      <td>the alzheimer s disease neuroimaging initiativ...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>e43f96ad-c523-4b18-99c9-7b87906a734d</td>\n      <td>our world in data</td>\n      <td>our world in data</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>7b050556-5a7a-4572-9f62-c480bee6a3cb</td>\n      <td>timss trends in international mathematics and ...</td>\n      <td>trends in international mathematics and scienc...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2a8a1b39-4c3c-435f-9d4b-5e855a5c18cf</td>\n      <td>education longitudinal study</td>\n      <td>national education longitudinal study</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>e0d7661e-c5d0-4ec6-923e-c3e694baaddc</td>\n      <td>the baltimore longitudinal study of aging</td>\n      <td>baltimore longitudinal study of aging blsa</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>2f3abc7c-408e-4893-a5c2-108afbe7cca9</td>\n      <td>the alzheimer s disease neuroimaging initiativ...</td>\n      <td>adni</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>8b79b4ad-5c8b-4eb5-9d1b-77ffac06615c</td>\n      <td>from alzheimer s disease neuroimaging initiati...</td>\n      <td>adni</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "pd.options.display.max_rows = 50\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame(columns = ['Id', 'PredictionString'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e4048e458757>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msub_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\projects\\env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\projects\\env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1856\u001b[0m                     \u001b[1;31m# must have conforming columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1858\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot set a row with mismatched columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "sub_df.loc[len(sub_df)] = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id PredictionString\n",
       "0  id             pred\n",
       "1  id             pred\n",
       "2  id             pred\n",
       "3  id             pred\n",
       "4  id             pred\n",
       "5  id             None"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>pred</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id</td>\n      <td>pred</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id</td>\n      <td>pred</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id</td>\n      <td>pred</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id</td>\n      <td>pred</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>id</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}