{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "    - I removed adni from labels, because it created noise in sentence labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import pickle\n",
    "\n",
    "train_example_names = [fn.split('.')[0] for fn in os.listdir('data/train')]\n",
    "test_example_names = [fn.split('.')[0] for fn in os.listdir('data/test')]\n",
    "\n",
    "metadata = pd.read_csv('data/train.csv')\n",
    "docIdx = train_example_names.copy()\n",
    "\n",
    "connection_tokens = {'s', 'of', 'and', 'in', 'on', 'for', 'from', 'the', 'act', 'coast', 'future', 'system', 'per'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Name Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    }
   ],
   "source": [
    "def text_cleaning(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text)).strip() # remove unnecessary literals\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = re.sub(\"\\s+\",\" \", text)\n",
    "\n",
    "    return text.lower().strip()\n",
    "\n",
    "def is_name_ok(text):\n",
    "    if len([c for c in text if c.isalnum()]) < 4:\n",
    "        return False\n",
    "    \n",
    "    tokens = [t for t in text.split(' ') if len(t) > 3]\n",
    "    tokens = [t for t in tokens if not t in connection_tokens]\n",
    "    if len(tokens) < 3:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "with open('data/all_preds_selected.csv', 'r') as f:\n",
    "    selected_pred_labels = f.readlines()\n",
    "    selected_pred_labels = [l.strip() for l in selected_pred_labels]\n",
    "\n",
    "existing_labels = [text_cleaning(x) for x in metadata['dataset_label']] +\\\n",
    "                  [text_cleaning(x) for x in metadata['dataset_title']] +\\\n",
    "                  [text_cleaning(x) for x in metadata['cleaned_label']] +\\\n",
    "                  [text_cleaning(x) for x in selected_pred_labels]\n",
    "\n",
    "\"\"\"to_remove = [\n",
    "    'frequently asked questions', 'total maximum daily load tmd', 'health care facilities',\n",
    "    'traumatic brain injury', 'north pacific high', 'droplet number concentration', 'great slave lake',\n",
    "    'census block groups'\n",
    "]\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"df = pd.read_csv(r'C:\\projects\\personal\\kaggle\\kaggle_coleridge_initiative\\string_search\\data\\gov_data.csv')\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "df['title'] = df.title.apply(text_cleaning)\n",
    "titles = list(df.title.unique())\n",
    "titles = [t for t in titles if not t in to_remove]\n",
    "df = pd.DataFrame({'title': titles})\n",
    "df = df.loc[df.title.apply(is_name_ok)]\n",
    "df = pd.concat([df, pd.DataFrame({'title': existing_labels})], ignore_index= True).reset_index(drop = True)\n",
    "titles = list(df.title.unique())\n",
    "df = pd.DataFrame({'title': titles})\n",
    "df['title'] = df.title.apply(text_cleaning)\"\"\"\n",
    "\n",
    "# Sort labels by length in ascending order\n",
    "#existing_labels = sorted(list(df.title.values), key = len, reverse = True)\n",
    "\n",
    "existing_labels = list(set(existing_labels))\n",
    "existing_labels = sorted(existing_labels, key = len, reverse = True)\n",
    "existing_labels = [l for l in existing_labels if len(l.split(' ')) < 15]\n",
    "#del df\n",
    "#existing_labels.remove('adni')\n",
    "\n",
    "print(len(existing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['national center for science and engineering statistics survey of science and engineering research facilities',\n",
       " 'national center for science and engineering statistics higher education research and development survey',\n",
       " 'national science foundation survey of graduate students and postdoctorates in science and engineering',\n",
       " 'national center for science and engineering statistics survey of industrial research and development',\n",
       " 'national oceanic and atmospheric administration optimum interpolation sea surface temperature']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cfsr', 'kegg', 'fema', 'pwv', 'csf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_labels[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe for tokens and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_example_by_name(name):\n",
    "    doc_path = os.path.join('data/train', name + '.json')\n",
    "    with open(doc_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_test_example_by_name(name):\n",
    "    doc_path = os.path.join('data/test', name + '.json')\n",
    "    with open(doc_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning_upper(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text)).strip() # remove unnecessary literals\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = re.sub(\"\\s+\",\" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def has_connected_uppercase(tokens):\n",
    "    if len(tokens) < 5:\n",
    "        return False\n",
    "\n",
    "    group_len = 0\n",
    "    n_long_tokens = 0\n",
    "    for token in tokens:\n",
    "        token_lower = token.lower()\n",
    "        if token[0].isupper():\n",
    "            if token_lower not in connection_tokens:\n",
    "                if len(token) > 2:\n",
    "                    n_long_tokens += 1\n",
    "\n",
    "                group_len += 1\n",
    "                if group_len > 2 and n_long_tokens > 0:\n",
    "                    return True\n",
    "\n",
    "        else:\n",
    "            if token_lower not in connection_tokens:\n",
    "                group_len = 0\n",
    "                n_long_tokens = 0\n",
    "\n",
    "    return False\n",
    "\n",
    "def sent_has_acronym(tokens):\n",
    "    # Acronym check\n",
    "    for token in tokens:\n",
    "        if len(token) > 3 and token.isupper():\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def sent_is_candidate(clean_sentence):\n",
    "    tokens = clean_sentence.split(' ')\n",
    "    \n",
    "    if sent_has_acronym(tokens):\n",
    "        return True\n",
    "    else:\n",
    "        return has_connected_uppercase(tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentences = []\n",
    "neg_sentences = []\n",
    "docs_no_pos = []\n",
    "total_sentences = 0\n",
    "label_use_counts = {l: 0 for l in existing_labels}\n",
    "\n",
    "\n",
    "def process_doc(doc_id):\n",
    "    \"\"\" Accept sentences with acronyms or uppercase words in succession as candidates.\n",
    "    From those candidates, positives are the ones that contain a label.\n",
    "\n",
    "    \"\"\"\n",
    "    global total_sentences\n",
    "    doc_json = load_train_example_by_name(doc_id)\n",
    "    doc_text = ' '.join([sec['text'] for sec in doc_json])\n",
    "    doc_has_pos = False\n",
    "\n",
    "    # Tokenize sentencewise\n",
    "    sentences = sent_tokenize(doc_text)\n",
    "    total_sentences += len(sentences)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        clean_sentence = text_cleaning_upper(sentence)\n",
    "        is_candidate = sent_is_candidate(clean_sentence)\n",
    "\n",
    "        has_label = False\n",
    "        if is_candidate:\n",
    "            clean_sentence_lower = clean_sentence.lower()\n",
    "            for clean_label in existing_labels:\n",
    "                if re.search(r'\\b{}\\b'.format(clean_label), clean_sentence_lower):\n",
    "                    has_label = True\n",
    "                    label_use_counts[clean_label] = label_use_counts[clean_label] + 1\n",
    "                    break\n",
    "        \n",
    "        # Store sentence in list if candidate\n",
    "        # Non-candidate sentences are discarded\n",
    "        if has_label:\n",
    "            pos_sentences.append(sentence)\n",
    "            doc_has_pos = True\n",
    "        elif is_candidate:\n",
    "            neg_sentences.append(sentence)\n",
    "\n",
    "    if not doc_has_pos:\n",
    "        docs_no_pos.append(doc_id)\n",
    "\n",
    "#process_doc('0026563b-d5b3-417d-bd25-7656b97a044f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Save Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos_size: 175743, neg_size: 795925, no pos label doc: 184, n_sentences: 4178921: 100%|â–ˆ| 14316/14316 [20:58<00:00, 11.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos size: 175743\n",
      "neg size: 795925\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "assert len(docIdx) > 0\n",
    "\n",
    "pos_sentences = []\n",
    "neg_sentences = []\n",
    "docs_no_pos = []\n",
    "total_sentences = 0\n",
    "\n",
    "pbar = tqdm(docIdx)\n",
    "for doc_id in pbar:\n",
    "    process_doc(doc_id)\n",
    "    pbar.set_description(\\\n",
    "        f'pos_size: {len(pos_sentences)}, neg_size: {len(neg_sentences)}, no pos label doc: {len(docs_no_pos)}, n_sentences: {total_sentences}')\n",
    "\n",
    "with open(f'data/selected_sentences/pos.pkl', 'wb') as f:\n",
    "    pickle.dump(pos_sentences, f)\n",
    "\n",
    "with open(f'data/selected_sentences/neg.pkl', 'wb') as f:\n",
    "    pickle.dump(neg_sentences, f)\n",
    "\n",
    "print(f'pos size: {len(pos_sentences)}')\n",
    "print(f'neg size: {len(neg_sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national water quality assesment                                                    0\n",
       "complexity science hub covid control strategies list                                0\n",
       "covid precision medicine analytics platform registry jh crown                       0\n",
       "characterizing health associated risks and your baseline disease in sars cov        0\n",
       "cas covid antiviral candidate compounds data                                        0\n",
       "                                                                                ...  \n",
       "ecls                                                                             7983\n",
       "nces                                                                             8080\n",
       "timss                                                                           13086\n",
       "apoe                                                                            14561\n",
       "adni                                                                            26690\n",
       "Length: 389, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(label_use_counts).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aac00fb1da9c94ab374af15aaaf3bdbaafa792d2239349bc70bec9f747decd69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
